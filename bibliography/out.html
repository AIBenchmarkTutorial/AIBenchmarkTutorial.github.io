<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Bibliography</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
  <style>
    body { font-family: "Times New Roman", serif; margin: 40px; line-height: 1.6; }
    .reference { font-family: "Roboto", sans-serif; margin-bottom: 1em; text-indent: -2em; padding-left: 2em; }
    .title { font-weight: bold; }
    .venue { font-style: italic; }
  </style>
</head>
<body>
  <h1>Bibliography</h1>
  <div class="reference">
    Kathrin Blagec, Jakob Kraiger, Wolfgang Frühwirt, and Matthias Samwald. 2023. 
<span class="title">Benchmark datasets driving artificial intelligence development fail to capture the needs of medical professionals</span>. 
<span class="venue">Journal of Biomedical Informatics, 137:104274.</span>
  </div>
  <div class="reference">
    Su Lin Blodgett, Gilsinia Lopez, Alexandra Olteanu, Robert Sim, and Hanna Wallach. 2021. 
<span class="title">Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets</span>. 
<span class="venue">In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1004–1015, Online. Association for Computational Linguistics.</span>
  </div>
  <div class="reference">
    Raunak Chowdhuri, Neil Deshmukh, and David Koplow. 2023. 
<span class="title">No, GPT4 can’t ace MIT: A Rebuttal of a Popular MIT Paper.</span>. 
  </div>
  <div class="reference">
    Naihao Deng, Xinliang Zhang, Siyang Liu, Winston Wu, Lu Wang, and Rada Mihalcea. 2023. 
<span class="title">You Are What You Annotate: Towards Better Models through Annotator Representations</span>. 
<span class="venue">In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 12475–12498, Singapore. Association for Computational Linguistics.</span>
  </div>
  <div class="reference">
    Yanai Elazar, Akshita Bhagia, Ian Magnusson, Abhilasha Ravichander, Dustin Schwenk, Alane Suhr, Pete Walsh, Dirk Groeneveld, Luca Soldaini, Sameer Singh, Hannaneh Hajishirzi, Noah Smith, and Jesse Dodge. 2024. 
<span class="title">What’s In My Big Data? International Conference on Representation Learning, 2024:7735–7790.</span>. 
  </div>
  <div class="reference">
    Maria Eriksson, Erasmo Purificato, Arman Noroozian, Joao Vinagre, Guillaume Chaslot, Emilia Gomez, and David Fernandez-Llorca. 2025. 
<span class="title">Can We Trust AI Benchmarks? An Interdisciplinary Review of Current Issues in AI Evaluation</span>. 
<span class="venue">arXiv:2502.06559 [cs].</span>
  </div>
  <div class="reference">
    Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt. 2023. 
<span class="title">Aligning AI With Shared Human Values</span>. 
<span class="venue">arXiv:2008.02275 [cs].</span>
  </div>
  <div class="reference">
    Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras, and Yejin Choi. 2022. 
<span class="title">CLIPScore: A Reference-free Evaluation Metric for Image Captioning</span>. 
<span class="venue">arXiv:2104.08718 [cs].</span>
  </div>
  <div class="reference">
    Valentin Hofmann, David Heineman, Ian Magnusson, Kyle Lo, Jesse Dodge, Maarten Sap, Pang Wei Koh, Chun Wang, Hannaneh Hajishirzi, and Noah A. Smith. 2025. 
<span class="title">Fluid Language Model Benchmarking</span>. 
<span class="venue">arXiv:2509.11106 [cs].</span>
  </div>
  <div class="reference">
    Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari Ostendorf, Ranjay Krishna, and Noah A. Smith. 2023. 
<span class="title">TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering</span>. 
<span class="venue">arXiv:2303.11897 [cs].</span>
  </div>
  <div class="reference">
    Bernard Koch, Emily Denton, Alex Hanna, and Jacob G. Foster. 2021. 
<span class="title">Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research</span>. 
<span class="venue">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks, 1.</span>
  </div>
  <div class="reference">
    Jerry W Lee, Patricia S. Jones, Yoshimitsu Mineyama, and Xinwei Esther Zhang. 2002. 
<span class="title">Cultural differences in responses to a likert scale</span>. 
<span class="venue">Research in nursing & health, 25 4:295–306.</span>
  </div>
  <div class="reference">
    Stephanie Lin, Jacob Hilton, and Owain Evans. 2022. 
<span class="title">TruthfulQA: Measuring How Models Mimic Human Falsehoods</span>. 
<span class="venue">arXiv:2109.07958 [cs].</span>
  </div>
  <div class="reference">
    R. Thomas McCoy, Ellie Pavlick, and Tal Linzen. 2019. 
<span class="title">Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference</span>. 
<span class="venue">In Anna Korhonen, David Traum, and Lluís Màrquez, editors, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3428–3448, Florence, Italy. Association for Computational Linguistics.</span>
  </div>
  <div class="reference">
    Drew McDermott, M. Mitchell Waldrop, B. Chandrasekaran, John McDermott, and Roger Schank. 1985. 
<span class="title">The Dark Ages of AI: A Panel Discussion at AAAI-84</span>. 
<span class="venue">AI Magazine, 6(3):122–122.</span>
  </div>
  <div class="reference">
    Timothy R. McIntosh, Teo Susnjak, Nalin Arachchilage, Tong Liu, Paul Watters, and Malka N. Halgamuge. 2025. 
<span class="title">Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence</span>. 
<span class="venue">IEEE Transactions on Artificial Intelligence:1–18. arXiv:2402.09880 [cs].</span>
  </div>
  <div class="reference">
    Melanie Mitchell. 2021. 
<span class="title">Why AI is Harder Than We Think</span>. 
<span class="venue">arXiv:2104.12871 [cs].</span>
  </div>
  <div class="reference">
    Luke Oakden-Rayner, Jared Dunnmon, Gustavo Carneiro, and Christopher Ré. 2019. 
<span class="title">Hidden Stratification Causes Clinically Meaningful Failures in Machine Learning for Medical Imaging</span>. 
<span class="venue">arXiv:1909.12475 [cs].</span>
  </div>
  <div class="reference">
    Juhyun Oh, Inha Cha, Michael Saxon, Hyunseung Lim, Shaily Bhatt, and Alice Oh. 2025. 
<span class="title">Culture is Everywhere: A Call for Intentionally Cultural Evaluation</span>. 
<span class="venue">In Christos Christodoulopoulos, Tanmoy Chakraborty, Carolyn Rose, and Violet Peng, editors, Findings of the Association for Computational Linguistics: EMNLP 2025, pages 19156–19168, Suzhou, China. Association for Computational Linguistics.</span>
  </div>
  <div class="reference">
    W James Popham. 1997. 
<span class="title">What’s wrong--and what’s right--with rubrics</span>. 
<span class="venue">Educational Leadership; Alexandria, 55(2):72–75.</span>
  </div>
  <div class="reference">
    Inioluwa Deborah Raji, Emily Denton, Emily M. Bender, Alex Hanna, and Amandalynne Paullada. 2022. 
<span class="title">AI and the Everything in the Whole Wide World Benchmark</span>. 
<span class="venue">In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)</span>
  </div>
  <div class="reference">
    Anka Reuel, Amelia Hardy, Chandler Smith, Max Lamparth, Malcolm Hardy, and Mykel J. Kochenderfer. 2024. 
<span class="title">BetterBench: assessing AI benchmarks, uncovering issues, and establishing best practices</span>. 
<span class="venue">In Proceedings of the 38th International Conference on Neural Information Processing Systems, volume 37, pages 21763–21813, Red Hook, NY, USA. Curran Associates Inc.</span>
  </div>
  <div class="reference">
    Michael Saxon, Ari Holtzman, Peter West, William Yang Wang, and Naomi Saphra. 2024. 
<span class="title">Benchmarks as Microscopes: A Call for Model Metrology</span>. 
<span class="venue">In First Conference on Language Modeling</span>
  </div>
  <div class="reference">
    Michael Saxon, Fatima Jahara, Mahsa Khoshnoodi, Yujie Lu, Aditya Sharma, and William Yang Wang. 2024. 
<span class="title">Who evaluates the evaluations? objectively scoring text-to-image prompt coherence metrics with T2iScoreScore (TS2)</span>. 
<span class="venue">In Proceedings of the 38th International Conference on Neural Information Processing Systems, volume 37, pages 85630–85657, Red Hook, NY, USA. Curran Associates Inc.</span>
  </div>
  <div class="reference">
    Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr. 2024. 
<span class="title">Quantifying Language Models’ Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting</span>. 
<span class="venue">arXiv:2310.11324 [cs].</span>
  </div>
  <div class="reference">
    Andrew D. Selbst, Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. 
<span class="title">Fairness and abstraction in sociotechnical systems</span>. 
<span class="venue">In FAT* 2019 - Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency, pages 59–68. Association for Computing Machinery, Inc.
1.
Hyeong Kyu Choi, Maxim Khanov, Hongxin Wei, and Yixuan Li. 2025. How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence. arXiv:2502.00678 [cs].</span>
  </div>
  <div class="reference">
    Shreya Shankar, J.D. Zamfirescu-Pereira, Bjoern Hartmann, Aditya Parameswaran, and Ian Arawjo. 2024. 
<span class="title">Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences</span>. 
<span class="venue">In Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology, pages 1–14, New York, NY, USA. Association for Computing Machinery.</span>
  </div>
  <div class="reference">
    Shivalika Singh, Yiyang Nan, Alex Wang, Daniel D’Souza, Sayash Kapoor, Ahmet Üstün, Sanmi Koyejo, Yuntian Deng, Shayne Longpre, Noah A. Smith, Beyza Ermis, Marzieh Fadaee, and Sara Hooker. 2025. 
<span class="title">The Leaderboard Illusion</span>. 
<span class="venue">arXiv:2504.20879 [cs].</span>
  </div>
  <div class="reference">
    Arjun Subramonian, Xingdi Yuan, Hal Daumé III, and Su Lin Blodgett. 2023. 
<span class="title">It Takes Two to Tango: Navigating Conceptualizations of NLP Tasks and Measurements of Performance</span>. 
<span class="venue">In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, Findings of the Association for Computational Linguistics: ACL 2023, pages 3234–3279, Toronto, Canada. Association for Computational Linguistics.</span>
  </div>
  <div class="reference">
    Wenda Xu, Guanglei Zhu, Xuandong Zhao, Liangming Pan, Lei Li, and William Yang Wang. 2024. 
<span class="title">Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement</span>. 
<span class="venue">arXiv:2402.11436 [cs].</span>
  </div>
  <div class="reference">
    Gregory Yauney and David Mimno. 2024. 
<span class="title">Stronger Random Baselines for In-Context Learning</span>. 
<span class="venue">In First Conference on Language Modeling</span>
  </div>
  <div class="reference">
    Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. 
<span class="title">HellaSwag: Can a Machine Really Finish Your Sentence? In Anna Korhonen, David Traum, and Lluís Màrquez, editors, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4791–4800, Florence, Italy</span>. 
<span class="venue">Association for Computational Linguistics.</span>
  </div>
  <div class="reference">
    Sarah J. Zhang, Samuel Florin, Ariel N. Lee, Eamon Niknafs, Andrei Marginean, Annie Wang, Keith Tyser, Zad Chin, Yann Hicke, Nikhil Singh, Madeleine Udell, Yoon Kim, Tonio Buonassisi, Armando Solar-Lezama, and Iddo Drori. 2023. 
<span class="title">Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models</span>. 
<span class="venue">arXiv:2306.08997 [cs].</span>
  </div>
</body>
</html>